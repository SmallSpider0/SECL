{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19877930f1d1442eac561d812ded0182",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/2000000 [00:00<?, ?sample/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms, models\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm  # 导入 tqdm.notebook 进度条\n",
    "\n",
    "# TODO：正常的协同训练流程，仅在所有客户端训练完成后聚合模型\n",
    "\n",
    "\n",
    "# 定义MLP模型\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MLP, self).__init__()\n",
    "        self.fc1 = nn.Linear(28 * 28, 256)\n",
    "        self.fc2 = nn.Linear(256, 64)\n",
    "        self.fc3 = nn.Linear(64, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 28 * 28)\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "# 数据集加载器\n",
    "def get_data_loaders(dataset_name, batch_size, data_dir=\"./data\", num_workers=10):\n",
    "    if not os.path.exists(data_dir):\n",
    "        os.makedirs(data_dir)\n",
    "\n",
    "    if dataset_name == \"MNIST\":\n",
    "        transform = transforms.Compose(\n",
    "            [transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))]\n",
    "        )\n",
    "        train_dataset = datasets.MNIST(\n",
    "            data_dir, train=True, download=True, transform=transform\n",
    "        )\n",
    "        test_dataset = datasets.MNIST(\n",
    "            data_dir, train=False, download=True, transform=transform\n",
    "        )\n",
    "    elif dataset_name == \"CIFAR10\":\n",
    "        transform_train = transforms.Compose(\n",
    "            [\n",
    "                transforms.RandomCrop(32, padding=4),\n",
    "                transforms.RandomHorizontalFlip(),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(\n",
    "                    (0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)\n",
    "                ),\n",
    "            ]\n",
    "        )\n",
    "        transform_test = transforms.Compose(\n",
    "            [\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(\n",
    "                    (0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)\n",
    "                ),\n",
    "            ]\n",
    "        )\n",
    "        train_dataset = datasets.CIFAR10(\n",
    "            data_dir, train=True, download=True, transform=transform_train\n",
    "        )\n",
    "        test_dataset = datasets.CIFAR10(\n",
    "            data_dir, train=False, download=True, transform=transform_test\n",
    "        )\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported dataset\")\n",
    "\n",
    "    # 划分训练数据集\n",
    "    subset_size = len(train_dataset) // num_workers\n",
    "    train_loaders = [\n",
    "        DataLoader(\n",
    "            Subset(train_dataset, range(i * subset_size, (i + 1) * subset_size)),\n",
    "            batch_size=batch_size,\n",
    "            shuffle=True,\n",
    "        )\n",
    "        for i in range(num_workers)\n",
    "    ]\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    return train_loaders, test_loader\n",
    "\n",
    "\n",
    "# 本地训练函数\n",
    "def local_train(model, device, train_loader, optimizer, criterion, local_epochs=1):\n",
    "    model.train()\n",
    "    for epoch in range(local_epochs):\n",
    "        for data, target in train_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            loss = criterion(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "\n",
    "# 模型聚合函数\n",
    "def aggregate_models(global_model, local_models):\n",
    "    global_dict = global_model.state_dict()\n",
    "    for k in global_dict.keys():\n",
    "        global_dict[k] = torch.stack(\n",
    "            [local_models[i][k].float() for i in range(len(local_models))], 0\n",
    "        ).mean(0)\n",
    "    global_model.load_state_dict(global_dict)\n",
    "\n",
    "\n",
    "def test(model, device, test_loader, criterion):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += criterion(output, target).item()  # sum up batch loss\n",
    "            pred = output.argmax(\n",
    "                dim=1, keepdim=True\n",
    "            )  # get the index of the max log-probability\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    accuracy = 100.0 * correct / len(test_loader.dataset)\n",
    "    return accuracy\n",
    "\n",
    "\n",
    "# 通用评估函数\n",
    "def eval(\n",
    "    model_name,\n",
    "    dataset_name,\n",
    "    batch_size=32,\n",
    "    total_data_limit=20000,\n",
    "    log_interval=10,\n",
    "    data_dir=\"./data\",\n",
    "    lr=0.01,\n",
    "    momentum=0.9,\n",
    "    num_workers=10,\n",
    "    local_epochs=1,\n",
    "):\n",
    "    use_cuda = torch.cuda.is_available()\n",
    "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "\n",
    "    train_loaders, test_loader = get_data_loaders(\n",
    "        dataset_name, batch_size, data_dir, num_workers\n",
    "    )\n",
    "\n",
    "    if model_name == \"MLP\" and dataset_name == \"MNIST\":\n",
    "        global_model = MLP().to(device)\n",
    "    elif model_name == \"ResNet18\" and dataset_name == \"CIFAR10\":\n",
    "        global_model = models.resnet18(num_classes=10).to(device)\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported model or dataset combination\")\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    all_data_amounts = []\n",
    "    all_accuracies = []\n",
    "    total_data = 0\n",
    "\n",
    "    with tqdm(total=total_data_limit, desc=\"Training\", unit=\"sample\") as pbar:\n",
    "        while total_data < total_data_limit:\n",
    "            local_models = []\n",
    "            for i in range(num_workers):\n",
    "                local_model = (\n",
    "                    MLP().to(device)\n",
    "                    if model_name == \"MLP\"\n",
    "                    else models.resnet18(num_classes=10).to(device)\n",
    "                )\n",
    "                local_model.load_state_dict(global_model.state_dict())\n",
    "                optimizer = optim.SGD(\n",
    "                    local_model.parameters(), lr=lr, momentum=momentum\n",
    "                )\n",
    "                local_train(\n",
    "                    local_model,\n",
    "                    device,\n",
    "                    train_loaders[i],\n",
    "                    optimizer,\n",
    "                    criterion,\n",
    "                    local_epochs,\n",
    "                )\n",
    "                local_models.append(local_model.state_dict())\n",
    "                total_data += len(train_loaders[i].dataset) * local_epochs\n",
    "                pbar.update(len(train_loaders[i].dataset))\n",
    "                pbar.set_postfix({\"Total Data\": total_data})\n",
    "\n",
    "            aggregate_models(global_model, local_models)\n",
    "            accuracy = test(global_model, device, test_loader, criterion)\n",
    "            print(\n",
    "                f\"Trained [{total_data} / {total_data_limit} samples]\\tAccuracy: {accuracy:.2f}%\"\n",
    "            )\n",
    "            all_accuracies.append(accuracy)\n",
    "            all_data_amounts.append(total_data)\n",
    "\n",
    "            if total_data >= total_data_limit:\n",
    "                break\n",
    "\n",
    "    return all_data_amounts, all_accuracies\n",
    "\n",
    "\n",
    "# 主函数调用\n",
    "# all_data_amounts, all_accuracies = eval(\n",
    "#     model_name='MLP',\n",
    "#     dataset_name='MNIST',\n",
    "#     batch_size=32,\n",
    "#     total_data_limit=120000,\n",
    "#     num_workers=10,\n",
    "#     local_epochs=1\n",
    "# )\n",
    "\n",
    "all_data_amounts, all_accuracies = eval(\n",
    "    model_name=\"ResNet18\",\n",
    "    dataset_name=\"CIFAR10\",\n",
    "    batch_size=32,\n",
    "    total_data_limit=2000000,\n",
    "    num_workers=10,\n",
    "    local_epochs=2,\n",
    ")\n",
    "\n",
    "# 保存数据到文件\n",
    "torch.save(\n",
    "    {\"data_amounts\": all_data_amounts, \"accuracies\": all_accuracies}, \"eval_results.pt\"\n",
    ")\n",
    "\n",
    "# 读取数据从文件\n",
    "loaded_data = torch.load(\"eval_results.pt\")\n",
    "loaded_data_amounts = loaded_data[\"data_amounts\"]\n",
    "loaded_accuracies = loaded_data[\"accuracies\"]\n",
    "\n",
    "# 验证读取的数据是否正确\n",
    "print(loaded_data_amounts)\n",
    "print(loaded_accuracies)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
